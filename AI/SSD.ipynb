{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyME13Ft/kCxk+WTcofaaAyX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Oxford Pet 데이터셋 가지고 Localization, Classification 하기\n","+ 본과정에서는 옥스퍼드 펫 데이터셋을 가지고 Localization (객체분류+BBox)수행합니다.\n","+ 1개의 이미지 입력을 받아 x,y,w,h 위치 좌표와 class 정보 출력하는 모델링을 만들어 보겠습니다.\n","+ 모델 생성시  2개 출력 (위치 정보와 class 정보)를 Concatenate로 1개로 묶게 되며\n","+ 커스텀 loss function 만들어 위치 정보와 class 정보에 대해 각각 loss를 계산해고 합치게 됩니다.\n","+ 상세한 내용은 아래에서 실습을 같이 해 보면서 설명하도록 하겠습니다."],"metadata":{"id":"-W_MvKSvNBer"}},{"cell_type":"markdown","source":["### 학습목차\n","1. Import modules\n","2. 데이터 준비하기\n","3. DataFrame에 이미지패스, class정보, 위치정보(x,y,w,h) 담자\n","4. 실제 이미지의 Bbox 그려보자(Localization)\n","5. CNN 모델로 Localization, Classification 학습하기\n","6. Pretrained MobileNetV2 사용하여 Localization, Classification 학습하기"],"metadata":{"id":"bVYznIgoNBbU"}},{"cell_type":"markdown","source":["# 1. import modules"],"metadata":{"id":"0923_xYFNBYY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJaIGEj0M7i9"},"outputs":[],"source":["## library import\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","from PIL import Image\n","from glob import glob\n","import shutil\n","import xml.etree.ElementTree as et\n","import random\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle"]},{"cell_type":"markdown","source":["# 2. 데이터 준비하기"],"metadata":{"id":"dROzC1JMNIL7"}},{"cell_type":"code","source":["## oxford_pet.zip이 보이는지 확인\n","glob('oxford_pet.zip')"],"metadata":{"id":"vLPgGbMgNAzl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 압축풀기\n","if not os.path.exists('./oxford_pet'):\n","  !unzip -q oxford_pet.zip -d oxford_pet"],"metadata":{"id":"SMUtraMXNAw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 압축이 풀린 directory 확인\n","!ls oxford_pet"],"metadata":{"id":"b3rQ0CGBNAuA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## directory 정보\n","cur_dir = os.getcwd()\n","data_dir = os.path.join(cur_dir, 'oxford_pet')\n","image_dir = os.path.join(data_dir, 'images')\n","bbox_dir = os.path.join(data_dir, 'annotations', 'xmls')  # BBOX 정보\n","seg_dir = os.path.join(data_dir, 'annotations', 'trimaps')  # Segmentation 정보"],"metadata":{"id":"mziqLyOWNArO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('data_dir:' ,data_dir)\n","print('image_dir:' ,image_dir)\n","print('bbox_dir:', bbox_dir)\n","print('seg_dir:', seg_dir)"],"metadata":{"id":"2IStsE3aNAoZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## image file 수 확인\n","image_files = [fname for fname in glob(image_dir +  '/*.jpg') if os.path.splitext(fname)[-1] == '.jpg']\n","print(len(image_files))"],"metadata":{"id":"iexNU4dCNAl2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## localization을 위한 annotation이 되어 있는 file의 수 확인\n","## 위의 이미지 갯수보다 annotation XML 파일 갯수가 적다. annotation XML 파일을 기준으로 해야함.\n","\n","bbox_files = [fname for fname in glob(bbox_dir +  '/*.xml') if os.path.splitext(fname)[-1] == '.xml']\n","len(bbox_files)"],"metadata":{"id":"0Qtgd_fzNAjA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 600 bbox와 매칭되는 이미지를 모우기 위한 새로운 폴더(new_images) 생성\n","\n","new_image_dir = os.path.join(data_dir, 'new_images')\n","os.makedirs(new_image_dir, exist_ok=True)\n","\n","print('new_images:', new_image_dir)"],"metadata":{"id":"RaQOqEmZNAgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 600 bbox 리스트 읽어 bbox 이름과 같은 이미지를 new_images 폴더에 복사한다.\n","\n","for bbox_filename in bbox_files:\n","  bbox_filename = bbox_filename.split('/')[-1]\n","  image_name = os.path.splitext(bbox_filename)[0]\n","  image_file = image_dir + '/' + image_name + '.jpg'\n","  # print(glob(image_file))\n","  shutil.copy(image_file, new_image_dir)"],"metadata":{"id":"1k7RJPn3NAe6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## new_images 폴더에 복사된 이미지 건수를 카운트한다.\n","\n","new_image_files = glob(new_image_dir + '/*')\n","len(new_image_files)"],"metadata":{"id":"50mzToFJNAa_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 600개의 새로 복사된 이미지 리스트\n","\n","new_image_files[:10]"],"metadata":{"id":"XwzDWZt3NAYE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. DataFrame에 이미지패스, class정보, 위치정보(x,y,w,h) 담자"],"metadata":{"id":"w27NMV5hNcP8"}},{"cell_type":"code","source":["## DataFrame 만들기\n","\n","pets_df = pd.DataFrame(new_image_files)\n","pets_df"],"metadata":{"id":"Sg1kKpXnNAVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 컬럼명 입력\n","\n","pets_df.columns = ['full_path']\n","pets_df.head(3)"],"metadata":{"id":"BqbnEX0bNASV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## full_path 컬럼에서 이미지 이름을 분리하여 file_name 컬럼명에 저장\n","\n","pets_df['file_name'] = pets_df['full_path'].str.split('/').str[-1]\n","pets_df.head(3)"],"metadata":{"id":"1GAizofUNAP4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## file_name 컬럼에서 라벨 분리하여 label 컬럼에 저장\n","\n","pets_df['label'] = pets_df['file_name'].str.replace('_\\d+','').str.split('.').str[0]"],"metadata":{"id":"T-pxa9XbNANI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pets_df.head(10)"],"metadata":{"id":"1AjomPh6NAKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 이미지 파일명을 입력으로 받아, 같은 이름과 xml 확장자로, 그리고 xml 위치로 변경해서 리턴\n","\n","def name_convert(col):\n","  bbox_fname = bbox_dir + '/' + col.replace('jpg','xml')\n","  return bbox_fname"],"metadata":{"id":"ZuGC3OlzNAHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## name_convert 함수 호출해서 이미지 파일명과 같은 이름의 xml 확장자로 만든다.\n","\n","pets_df['bbox_full_path'] = pets_df['file_name'].apply(name_convert)\n","pets_df.head(3)"],"metadata":{"id":"C_8esuOZNAE6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## pets_df 데이터 구조 파악\n","\n","pets_df.info()"],"metadata":{"id":"rV1PXPqENACH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## label 분포 확인\n","## 각 class마다 200개 이미지 구성\n","\n","pets_df['label'].value_counts()"],"metadata":{"id":"jfUbCUsMM__o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## bbox_full_path 컬럼의 첫번째 데이터 가져오고 해당 내용 보기\n","\n","sample_xml_file = pets_df.loc[0, 'bbox_full_path']\n","print(sample_xml_file)\n","\n","!cat /content/oxford_pet/annotations/xmls/boxer_190.xml"],"metadata":{"id":"iTmifYxwM_8-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 1. xml Annotation 파일 읽어 이지미 크기와 Bounding box 위치을 파악\n","## 2. xmin, ymin, xmax, ymax 형태를  x, y(중앙), w, h 형태로 변환하여 저장\n","\n","def xml_annot_getxywh(xmlfile):\n","  tree = et.parse(xmlfile)\n","\n","  width = float(tree.find('./size/width').text)\n","  height = float(tree.find('./size/height').text)\n","  xmin = float(tree.find('./object/bndbox/xmin').text)\n","  ymin = float(tree.find('./object/bndbox/ymin').text)\n","  xmax = float(tree.find('./object/bndbox/xmax').text)\n","  ymax = float(tree.find('./object/bndbox/ymax').text)\n","  xc = (xmin + xmax) / 2.\n","  yc = (ymin + ymax) / 2.\n","  x = xc / width\n","  y = yc / height\n","  w = (xmax - xmin) / width\n","  h = (ymax - ymin) / height\n","\n","  return x, y, w, h"],"metadata":{"id":"MvBK3JtQM_6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 샘플 xml 파일에 대한 x, y, w, h 얻어오기\n","\n","xml_annot_getxywh(sample_xml_file)"],"metadata":{"id":"eUf4YCJdM_3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pets_df"],"metadata":{"id":"LwReJsExM_1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## xml Annot 파일의 x, y, w, h 위치 정보를 가져와 DataFrame에 저장한다.\n","\n","pets_df['xywh'] = pets_df['bbox_full_path'].apply(xml_annot_getxywh)\n","pets_df.head()"],"metadata":{"id":"1Ea3zchAM_ys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 튜플로 저장된 xywh 컬럼 값들을 하나씩 x, y, w, h 컬럼에 저장한다.\n","\n","pets_df['x'] = pets_df['xywh'].str[0]\n","pets_df['y'] = pets_df['xywh'].str[1]\n","pets_df['w'] = pets_df['xywh'].str[2]\n","pets_df['h'] = pets_df['xywh'].str[3]"],"metadata":{"id":"nCPbVzABM_wB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pets_df"],"metadata":{"id":"dS4SBFavM_tj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## label에 대한 라벨인코딩 수행\n","from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","pets_df['label_conv'] = le.fit_transform(pets_df['label'])\n","le.classes_"],"metadata":{"id":"YVVR9NShM_q9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pets_df.head(3)"],"metadata":{"id":"iDMdgGi0M_oL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## class와 idx 간의 변환\n","\n","class2idx = { label : idx for idx, label in enumerate(le.classes_) }\n","idx2class = { idx :label for idx, label in enumerate(le.classes_) }"],"metadata":{"id":"tTaZtpJZM_lS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(class2idx)\n","print(idx2class)"],"metadata":{"id":"umZh8OxeM_i8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 이미지 패스 리스트 만들기\n","\n","images_list = pets_df['full_path'].values"],"metadata":{"id":"kE3KZKj-M_gX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 이미지 파일 리스트에서 이미지 패스로 해당 이미지 읽고 리스트에 넣는다.\n","## 이미지 resize로 맞추지 않으면 뒤쪽에서 Tensor에러 발생한다.\n","\n","x_image_list = []\n","\n","for fname in images_list:\n","  image = Image.open(fname)\n","  image = image.resize((224,224))\n","  image = np.array(image)\n","\n","  x_image_list.append(image)\n","\n","x_image_list = np.array(x_image_list)"],"metadata":{"id":"YSyx99POM_d5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 전체 이미지 리스트 형태 보기\n","\n","x_image_list.shape, type(x_image_list)"],"metadata":{"id":"621SRjY-M_bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 이미지 라벨값과 bbox 위치값을 같이 저장한다.\n","\n","y1_label = pets_df[['x', 'y', 'w', 'h', 'label_conv']].values"],"metadata":{"id":"XWg2OtxgM_Zc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y1_label[:4]"],"metadata":{"id":"50eGqoiWM_Xu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMG_SIZE = 224\n","N_BBOX = len(x_image_list)\n","N_TRAIN = 500\n","N_VAL = N_BBOX - N_TRAIN"],"metadata":{"id":"IBRWabONM_UJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Annotation XML 파일 갯수로 리스트 만들고 Shuffle하고 500개 Train set과 100개 Valid set으로 나눈다.\n","\n","shuffle_list = list(range(N_BBOX))\n","random.shuffle(shuffle_list)\n","\n","train_idx_list = shuffle_list[:N_TRAIN]\n","val_idx_list = shuffle_list[N_TRAIN:]"],"metadata":{"id":"gIODnPDLM_Rw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Train set idx 보기\n","train_idx_list[:10]"],"metadata":{"id":"WXVNN15QM_Pa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## train 데이터셋 만들기\n","\n","train_image_list = x_image_list[train_idx_list]\n","train_label = y1_label[train_idx_list]"],"metadata":{"id":"PMbRf1CIM_M9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_image_list.shape, train_label.shape"],"metadata":{"id":"-YfoUzqzM_Ka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## valid 데이터셋 만들기\n","\n","valid_image_list = x_image_list[val_idx_list]\n","valid_label = y1_label[val_idx_list]"],"metadata":{"id":"IUrAkE6BOLGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_image_list.shape, valid_label.shape"],"metadata":{"id":"KBG1fwFsOLDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Train / Valid Dataset 만들기\n","\n","train_dataset_image = tf.data.Dataset.from_tensor_slices((train_image_list, train_label))\n","train_dataset = train_dataset_image.batch(16).shuffle(1000).repeat()\n","\n","valid_dataset_image = tf.data.Dataset.from_tensor_slices((valid_image_list, valid_label))\n","valid_dataset = valid_dataset_image.batch(16).repeat()"],"metadata":{"id":"7g1AXZ8oOLBQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. 실제 이미지의 Bbox 그려보자(Localization)"],"metadata":{"id":"yvUEV4S1OQxx"}},{"cell_type":"code","source":["## Hyper Parameters\n","\n","N_CLASS = len(class2idx)\n","N_EPOCHS = 40\n","N_BATCH = 16\n","IMG_SIZE = 224\n","learning_rate = 0.0001\n","\n","steps_per_epoch = N_TRAIN / N_BATCH\n","validation_steps = int(np.ceil(N_VAL / N_BATCH))"],"metadata":{"id":"rBQ42ylXOK-R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## valid_dataset에서 1개 가져와 분석해 보자\n","## 이미지와 라벨로 받고 라벨은 다시 실제 라벨과 x,y,w,h 위치 값으로 나뉜다.\n","\n","for image, label in valid_dataset.take(1):\n","  print(image.shape)\n","  print(label.shape)\n","  print(label[:, :4].shape)\n","  print(label[:, -1].shape)\n","  break\n"],"metadata":{"id":"POi-z8-SOK7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## valid dataset에서 1개의 image와 bbox, label 를 읽어서 확인\n","\n","cnt = 0\n","for image, label in valid_dataset.take(1):\n","\n","    ''' matplotlib Rectangle 이용하여 사각형 그릴 경우,\n","    그림을 그리기 위해서 bbox의 왼쪽 아래 (xmin, ymin) 꼭지점 좌표를 계산하고,\n","    xmin, ymin, w, h 각각을 image size에 맞게 scaling'''\n","\n","    # x, y(중앙), w, h 형태를 xmin, ymin, w, h 형태로 변환해야 함.\n","\n","    x = label[:,0]\n","    y = label[:,1]\n","    w = label[:,2]\n","    h = label[:,3]\n","    classes = label[:,4].numpy()\n","\n","    xmin = x[0].numpy() - w[0].numpy()/2.\n","    ymin = y[0].numpy() - h[0].numpy()/2.\n","    rect_x = int(xmin * IMG_SIZE)\n","    rect_y = int(ymin * IMG_SIZE)\n","    rect_w = int(w[0].numpy() * IMG_SIZE)\n","    rect_h = int(h[0].numpy() * IMG_SIZE)\n","\n","    ## 그림 그리기\n","    rect = Rectangle((rect_x, rect_y), rect_w, rect_h, fill=False, color='red')\n","    plt.axes().add_patch(rect)\n","    plt.title(f'{classes[0]}, {idx2class[classes[0]]}')\n","    plt.imshow(image[0])\n","    plt.show()"],"metadata":{"id":"-Z2K0j0AOK5E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. CNN 모델로 Localization 학습하기"],"metadata":{"id":"3RPYEHvJOh9t"}},{"cell_type":"code","source":["# Functional API를 사용하여 모델 생성\n","# 입력과 출력 레이어에 이름 붙여주자!!!\n","\n","def create_model():\n","\n","    # 입력\n","    inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='inputs')\n","\n","    # 컨볼루션\n","    conv = tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='SAME', name='conv2d_layer_1')(inputs)\n","    pool = tf.keras.layers.MaxPooling2D((2, 2), padding='SAME', name='maxpool_layer_1')(conv)\n","\n","    conv = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='SAME', name='conv2d_layer_2')(inputs)\n","    pool = tf.keras.layers.MaxPooling2D((2, 2), padding='SAME', name='maxpool_layer_2')(conv)\n","\n","    conv = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='SAME', name='conv2d_layer_3')(inputs)\n","    pool = tf.keras.layers.MaxPooling2D((2, 2), padding='SAME', name='maxpool_layer_3')(conv)\n","\n","    conv = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='SAME', name='conv2d_layer_4')(inputs)\n","    pool = tf.keras.layers.MaxPooling2D((2, 2), padding='SAME', name='maxpool_layer_4')(conv)\n","    flat = tf.keras.layers.Flatten(name='flatten_layer')(pool)\n","\n","    # 출력\n","    dense1 = tf.keras.layers.Dense(128, activation='relu')(flat)\n","    outputs_xywh = tf.keras.layers.Dense(4, activation='sigmoid', name='get_xywh')(dense1)  # 4개 X, Y, W, H 좌표\n","    outputs_classes = tf.keras.layers.Dense(N_CLASS, activation='softmax', name='get_classes')(dense1)  # 6개 클래스 레이블\n","\n","    concat = tf.keras.layers.Concatenate()([outputs_xywh, outputs_classes])  # 총 10개의 출력\n","\n","    # 모델\n","    model = tf.keras.models.Model(inputs=inputs, outputs=concat)\n","\n","    return model\n"],"metadata":{"id":"sjk2oUzyOK2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create model, compile & summary\n","model = create_model()\n","model.summary()"],"metadata":{"id":"IfPK4uPwOKzn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 모델의 입력과 출력을 나타내는 텐서\n","## model.output : (None, 10) ? --> 4개의 x, y, w, h 와 class 6개 one-hot-encoding\n","\n","print(model.input)\n","print(model.output)"],"metadata":{"id":"CirfucYqOKw4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 모델 흐름도 그리기\n","![layers1](https://github.com/gzone2000/TEMP_TEST/raw/master/BB/multi_output_cnn1.png)"],"metadata":{"id":"pjn2mtfvOmhx"}},{"cell_type":"code","source":["# 커스텀 Loss Function\n","# 자동으로 y_true와 y_pred 두개 인자가 들어옴.\n","# 정답과 예측값은 10개의 값들로 구성됨 : 앞 4개(X, Y, H, W) + 뒤 6개(원핫인코딩된 Class 종류)\n","# 앞 4개(X, Y, H, W)와 뒤 6개(원핫인코딩된 Class 종류) 각각에 대해서 Loss 함수를 구하고 합쳐야 한다.\n","# cls_labels는 정답으로 숫자 1자리로 되어 있어 one-hot-encoding 되어야 함(Sparse_categorical_crossentropy 필요)\n","# 하지만, y_pred 경우 이미 6개 Class에 대해 one_hot_encoding 된 상태로 예측값을 주므로 인덱스 위치를 잘 찾아 비교해야함.\n","\n","def loss_fn(y_true, y_pred):\n","  loc_labels = y_true[:,:4] # y_true[:,:4] -> 정답 bbox 4개 위치 값\n","  loc_preds = y_pred[:,:4] # y_pred[:,:4] -> 예측값 bbox 4개 위치 값\n","\n","  cls_labels = tf.cast(y_true[:,4:], tf.int64) # y_true[:, 4:] -> 정답 class 1개 값이어서 원핫인코딩 필요\n","  cls_preds = y_pred[:,4:] # y_pred[:,4:] -> 예측값 class 1개값에 대해 이미 6개로 one-hot-encoding 되어 있음\n","\n","  loc_loss = tf.keras.losses.MeanSquaredError()(loc_labels, loc_preds)  # 회귀 : MSE\n","  cls_loss = tf.keras.losses.SparseCategoricalCrossentropy()(cls_labels, cls_preds)  # 분류 : Crossentropy\n","\n","  # 2개의 loss 함쳐 리터\n","  return cls_loss + 5*loc_loss"],"metadata":{"id":"wVWeJI1yOKuC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 컴파일\n","\n","## learning rate scheduing\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n","                                                          decay_steps=steps_per_epoch*10,\n","                                                          decay_rate=0.5,\n","                                                          staircase=True)\n","\n","## optimizer는 RMSprop, loss는 mean squared error 사용\n","model.compile(tf.keras.optimizers.RMSprop(lr_schedule, momentum=0.9), loss=loss_fn, metrics=['accuracy'])"],"metadata":{"id":"Mo9aYK_eOKrY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## callbacks : EarlyStopping, ModelCheckpoint\n","es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","mc = tf.keras.callbacks.ModelCheckpoint('best_model_{val_loss:.2f}.h5', monitor='val_loss', save_best_only=True, verbose=1)"],"metadata":{"id":"RDCgeNz_OKo6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Train!\n","model.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n","         epochs=N_EPOCHS,\n","         validation_data=valid_dataset,\n","         validation_steps=validation_steps,\n","         callbacks=[es, mc])\n"],"metadata":{"id":"Ca978FLoOKlu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. Pretrained MobileNetV2 사용하여 학습하기"],"metadata":{"id":"eEtfqT_NOwTC"}},{"cell_type":"code","source":["from tensorflow.keras import models\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D"],"metadata":{"id":"R7MNmadmOKjI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))"],"metadata":{"id":"VF2AN-sUOKgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mobilenetv2.summary()"],"metadata":{"id":"nNMgEeJKOKdr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Functional API를 사용하여 모델 생성\n","# 입력과 출력 레이어에 이름 붙여주자!!!\n","\n","def create_mv_model():\n","\n","    # mobilenetv2\n","    globalavgpool = tf.keras.layers.GlobalAveragePooling2D()(mobilenetv2.output)\n","\n","    # 출력\n","    dense1 = tf.keras.layers.Dense(128, activation='relu')(globalavgpool)\n","    outputs_xywh = tf.keras.layers.Dense(4, activation='sigmoid', name='get_xywh')(dense1)\n","    outputs_classes = tf.keras.layers.Dense(N_CLASS, activation='softmax', name='get_classes')(dense1)\n","\n","    concat = tf.keras.layers.Concatenate()([outputs_xywh, outputs_classes])\n","\n","    # 모델\n","    model = tf.keras.models.Model(inputs=mobilenetv2.input, outputs=concat)\n","\n","    return model"],"metadata":{"id":"yMs0x6-sOKaw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create model, compile & summary\n","model = create_mv_model()\n","model.summary()"],"metadata":{"id":"Qbn4azxmOKYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 커스텀 Loss Function\n","# 자동으로 y_true와 y_pred 두개 인자가 들어옴.\n","# 정답과 예측값은 10개의 값들로 구성됨 : 앞 4개(X, Y, H, W) + 뒤 6개(원핫인코딩된 Class 종류)\n","# 앞 4개(X, Y, H, W)와 뒤 6개(원핫인코딩된 Class 종류) 각각에 대해서 Loss 함수를 구하고 합쳐야 한다.\n","# cls_labels는 정답으로 숫자 1자리로 되어 있어 one-hot-encoding 되어야 함(Sparse_categorical_crossentropy 필요)\n","# 하지만, y_pred 경우 이미 6개 Class에 대해 one_hot_encoding 된 상태로 예측값을 주므로 인덱스 위치를 잘 찾아 비교해야함.\n","\n","def loss_fn(y_true, y_pred):\n","  loc_labels = y_true[:,:4] # y_true[:,:4] -> 정답 bbox 4개 위치 값\n","  loc_preds = y_pred[:,:4] # y_pred[:,:4] -> 예측값 bbox 4개 위치 값\n","\n","  cls_labels = tf.cast(y_true[:,4:], tf.int64) # y_true[:, 4:] -> 정답 class 1개 값이어서 원핫인코딩 필요\n","  cls_preds = y_pred[:,4:] # y_pred[:,4:] -> 예측값 class 1개값에 대해 이미 6개로 one-hot-encoding 되어 있음\n","\n","  loc_loss = tf.keras.losses.MeanSquaredError()(loc_labels, loc_preds)  # 회귀 : MSE\n","  cls_loss = tf.keras.losses.SparseCategoricalCrossentropy()(cls_labels, cls_preds)  # 분류 : Crossentropy\n","\n","  # 2개의 loss 함쳐 리터\n","  return cls_loss + 5*loc_loss"],"metadata":{"id":"l0OjLk_zOKVc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 컴파일\n","\n","## learning rate scheduing\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n","                                                          decay_steps=steps_per_epoch*10,\n","                                                          decay_rate=0.5,\n","                                                          staircase=True)\n","\n","## optimizer는 RMSprop, loss는 mean squared error 사용\n","model.compile(tf.keras.optimizers.RMSprop(lr_schedule, momentum=0.9), loss=loss_fn, metrics=['accuracy'])"],"metadata":{"id":"io9iqqOhOKTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## callbacks : EarlyStopping, ModelCheckpoint\n","es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n","mc = tf.keras.callbacks.ModelCheckpoint('best_model_{val_loss:.2f}.h5', monitor='val_loss', save_best_only=True, verbose=1)"],"metadata":{"id":"76UpKY4_OKQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Train!\n","model.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n","         epochs=N_EPOCHS,\n","         validation_data=valid_dataset,\n","         validation_steps=validation_steps,\n","         callbacks=[es, mc])\n"],"metadata":{"id":"btGCfbfpOKNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# validation data 일부 읽어와 예측해 보고 Class와 Bbox에 대한 정답과 예측 확인\n","## 정답은 빨간색 box, 예측은 파란색 box\n","\n","idx = 2\n","num_imgs = validation_steps\n","\n","# val_dataset 포맷: (None, 224, 224, 3), (None, 5)\n","for val_data, val_gt in valid_dataset.take(num_imgs):\n","\n","    ## 정답 box 그리기\n","    x = val_gt[:,0]\n","    y = val_gt[:,1]\n","    w = val_gt[:,2]\n","    h = val_gt[:,3]\n","    gt_class = val_gt[:,4]\n","\n","    gt_class_num = gt_class[idx]\n","    xmin = x[idx].numpy() - w[idx].numpy()/2.\n","    ymin = y[idx].numpy() - h[idx].numpy()/2.\n","    rect_x = int(xmin * IMG_SIZE)\n","    rect_y = int(ymin * IMG_SIZE)\n","    rect_w = int(w[idx].numpy() * IMG_SIZE)\n","    rect_h = int(h[idx].numpy() * IMG_SIZE)\n","\n","    rect = Rectangle((rect_x, rect_y), rect_w, rect_h, fill=False, color='red')\n","    plt.axes().add_patch(rect)\n","\n","    ## 예측 box 그리기\n","    ## validation set에 대해서 bounding box 예측\n","    prediction = model.predict(val_data) # prediction.shape : (None, 10)\n","    pred_x = prediction[:,0]\n","    pred_y = prediction[:,1]\n","    pred_w = prediction[:,2]\n","    pred_h = prediction[:,3]\n","    pred_class = np.argmax(prediction[:,4:], axis=1)\n","\n","    pred_class_num = pred_class[idx]\n","    pred_xmin = pred_x[idx] - pred_w[idx]/2.\n","    pred_ymin = pred_y[idx] - pred_h[idx]/2.\n","    pred_rect_x = int(pred_xmin * IMG_SIZE)\n","    pred_rect_y = int(pred_ymin * IMG_SIZE)\n","    pred_rect_w = int(pred_w[idx] * IMG_SIZE)\n","    pred_rect_h = int(pred_h[idx] * IMG_SIZE)\n","\n","    pred_rect = Rectangle((pred_rect_x, pred_rect_y), pred_rect_w, pred_rect_h,\n","                         fill=False, color='blue')\n","    plt.axes().add_patch(pred_rect)\n","\n","    ## image와 bbox 함께 출력\n","    plt.title(f'GT : {gt_class_num}, Pred : {pred_class_num}')\n","    plt.imshow(val_data[idx])\n","    plt.show()"],"metadata":{"id":"kh8t3JW2OKKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k1s_aQoKOKIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","\n","# 사전 학습된 SSD 모델 로드\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'ssd300_vgg16', pretrained=True)\n","model.eval()\n","\n","# COCO 클래스 이름 로드\n","CLASSES = [\n","    \"__background__\", \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n","    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\",\n","    \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\",\n","    \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\",\n","    \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\",\n","    \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\",\n","    \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\", \"laptop\", \"mouse\",\n","    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\",\n","    \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n","]\n","\n","# 이미지 전처리\n","def transform_image(image):\n","    transform = transforms.Compose([\n","        transforms.Resize((300, 300)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","    return transform(image).unsqueeze(0)\n","\n","# 바운딩 박스 그리기\n","def draw_boxes(image, boxes, labels, scores, threshold=0.5):\n","    image = np.array(image)\n","    for box, label, score in zip(boxes, labels, scores):\n","        if score >= threshold:\n","            xmin, ymin, xmax, ymax = box\n","            cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (255, 0, 0), 2)\n","            label_text = f\"{CLASSES[label]}: {score:.2f}\"\n","            cv2.putText(image, label_text, (int(xmin), int(ymin) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n","    return image\n","\n","# 폴더 내 이미지 처리 및 저장\n","def process_images(input_folder, output_folder):\n","    # 입력 폴더 내 모든 파일을 순회\n","    for filename in os.listdir(input_folder):\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            image_path = os.path.join(input_folder, filename)\n","            image = Image.open(image_path).convert('RGB')\n","\n","            # 이미지 변환 및 모델 예측\n","            input_tensor = transform_image(image)\n","            with torch.no_grad():\n","                detections = model(input_tensor)[0]\n","\n","            # 결과 처리\n","            boxes = detections['boxes'].cpu().numpy()\n","            labels = detections['labels'].cpu().numpy()\n","            scores = detections['scores'].cpu().numpy()\n","\n","            # 바운딩 박스 그리기\n","            result_image = draw_boxes(image, boxes, labels, scores)\n","\n","            # 결과 이미지 저장\n","            if not os.path.exists(output_folder):\n","                os.makedirs(output_folder)\n","            result_image_path = os.path.join(output_folder, filename)\n","            cv2.imwrite(result_image_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))\n","            print(f\"결과 이미지가 {result_image_path}에 저장되었습니다.\")\n","\n","# 입력 및 출력 폴더 경로 설정\n","input_folder = 'input_images'  # 입력 이미지 폴더 경로\n","output_folder = 'output_images'  # 결과 이미지 저장 폴더 경로\n","\n","# 이미지 처리 및 저장 함수 호출\n","process_images(input_folder, output_folder)\n"],"metadata":{"id":"FtukNPkKOKFq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ceRQUQ2sOKCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4Gc85ogUOJ_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jp9HqRkdOJ9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pauEGCR2OJ7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U1SWwrEWOJ4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FN2DDdq5OJ2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a1hWQzlsOJz0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rKtht7SHOJw_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sbse-wasOJum"},"execution_count":null,"outputs":[]}]}